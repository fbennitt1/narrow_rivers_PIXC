{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc7082fc-f80f-4bcb-9a9d-b37a8d507d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14045778-cca2-4e50-b24b-c12976aa874a",
   "metadata": {},
   "source": [
    "### Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "829b1917-0f8f-4289-bfa1-ecca557bb598",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdata_path = '/nas/cee-water/cjgleason/fiona/narrow_rivers_PIXC/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78860b4e-0541-4b55-b8cc-44cef6d8057c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 150, 200, 500, 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4832615e-9866-4480-9791-4df317865e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dtypes for lookup tables to preserve leading zeros\n",
    "dtype_dic= {'HUC4': str, 'HUC2': str, 'toBasin': str, 'level': str}\n",
    "# Read in HUC lookup table\n",
    "lookup = pd.read_csv(os.path.join(mdata_path,\n",
    "                                  'HUC4_lookup_no_great_lakes.csv'),\n",
    "                     dtype=dtype_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a59c68e-b40a-4ee3-bad5-42b1f2d5085f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_slurm = lookup['slurm_index'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fcd984-8286-4d03-9371-02cca195c0b3",
   "metadata": {},
   "source": [
    "### NHD_prepped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d7b03005-9c2a-4f24-af1e-ed0a7a015f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/nas/cee-water/cjgleason/fiona/narrow_rivers_PIXC_data/NHD_prepped/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "349bee27-c238-4476-9910-ff8e58f77ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(max_slurm+1):\n",
    "    # Get current HUC2 and HUC4 IDs\n",
    "    huc2 = 'HUC2_' + lookup.loc[i,'HUC4'][0:2]\n",
    "    huc4 = 'NHDPLUS_H_' + lookup.loc[i,'HUC4'] + '_HU4_GDB'\n",
    "    \n",
    "    # Set data filepath\n",
    "    file_path = os.path.join(data_path, huc2, huc4 + '_prepped.parquet')\n",
    "    \n",
    "    # Read in\n",
    "    basin = gpd.read_parquet(file_path)\n",
    "    \n",
    "    ## Bin reaches by width, set to string for parquet\n",
    "    basin['Bin_Min'] = pd.cut(basin['WidthM_Min'], bins).astype(str)\n",
    "    basin['Bin_Max'] = pd.cut(basin['WidthM_Max'], bins).astype(str)\n",
    "    \n",
    "    # Write back out\n",
    "    basin.to_parquet(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc9555b-8e1b-4e1c-8eca-a096b3a09f2f",
   "metadata": {},
   "source": [
    "### NHD_prepped_segmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5a1c7f65-ec4e-48a8-9085-e9020f869645",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/nas/cee-water/cjgleason/fiona/narrow_rivers_PIXC_data/NHD_prepped_segmented/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5dd7238c-ef80-4c33-92c2-a6f6b25d2cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(max_slurm+1):\n",
    "    # Get current HUC2 and HUC4 IDs\n",
    "    huc2 = 'HUC2_' + lookup.loc[i,'HUC4'][0:2]\n",
    "    huc4 = 'NHDPLUS_H_' + lookup.loc[i,'HUC4'] + '_HU4_GDB'\n",
    "    \n",
    "    # Set data filepath\n",
    "    file_path = os.path.join(data_path, huc2, huc4 + '_prepped_segmented.parquet')\n",
    "    \n",
    "    # Read in\n",
    "    basin = gpd.read_parquet(file_path)\n",
    "    \n",
    "    ## Bin reaches by width, set to string for parquet\n",
    "    basin['Bin_Min'] = pd.cut(basin['WidthM_Min'], bins).astype(str)\n",
    "    basin['Bin_Max'] = pd.cut(basin['WidthM_Max'], bins).astype(str)\n",
    "    \n",
    "    # Write back out\n",
    "    basin.to_parquet(file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-narrowPIXC]",
   "language": "python",
   "name": "conda-env-.conda-narrowPIXC-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
